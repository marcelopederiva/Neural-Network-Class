{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFi1P1DT4FgS"
   },
   "source": [
    "# Solving a Maze with Deep Reinforcement Learning\n",
    "# FEEC/Unicamp - July/2020\n",
    "# Based on https://www.samyzaf.com/ML/rl/qmaze.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjhi5kdG4FgT"
   },
   "source": [
    "### Importações e definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aDpGQDz4Fg0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "import os, sys, time, datetime, json, random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD , Adam, RMSprop\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQs4V1wY_jJS"
   },
   "outputs": [],
   "source": [
    "visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n",
    "rat_mark = 0.5      # The current rat cell will be painted by gray 0.5\n",
    "LEFT = 0\n",
    "UP = 1\n",
    "RIGHT = 2\n",
    "DOWN = 3\n",
    "\n",
    "# Actions dictionary\n",
    "actions_dict = {\n",
    "    LEFT: 'left',\n",
    "    UP: 'up',\n",
    "    RIGHT: 'right',\n",
    "    DOWN: 'down',\n",
    "}\n",
    "\n",
    "num_actions = len(actions_dict)\n",
    "\n",
    "# Exploration factor\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1gPgFfQAMu_"
   },
   "outputs": [],
   "source": [
    "# maze is a 2d Numpy array of floats between 0.0 to 1.0\n",
    "# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n",
    "# rat = (row, col) initial rat position (defaults to (0,0))\n",
    "\n",
    "class Qmaze(object):\n",
    "    def __init__(self, maze, rat=(0,0)):\n",
    "        self._maze = np.array(maze)\n",
    "        nrows, ncols = self._maze.shape\n",
    "        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n",
    "        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n",
    "        self.free_cells.remove(self.target)\n",
    "        if self._maze[self.target] == 0.0:\n",
    "            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n",
    "        if not rat in self.free_cells:\n",
    "            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n",
    "        self.reset(rat)\n",
    "\n",
    "    def reset(self, rat):\n",
    "        self.rat = rat\n",
    "        self.maze = np.copy(self._maze)\n",
    "        nrows, ncols = self.maze.shape\n",
    "        row, col = rat\n",
    "        self.maze[row, col] = rat_mark\n",
    "        self.state = (row, col, 'start')\n",
    "        self.min_reward = -0.5 * self.maze.size\n",
    "        self.total_reward = 0\n",
    "        self.visited = set()\n",
    "\n",
    "    def update_state(self, action):\n",
    "        nrows, ncols = self.maze.shape\n",
    "        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n",
    "\n",
    "        if self.maze[rat_row, rat_col] > 0.0:\n",
    "            self.visited.add((rat_row, rat_col))  # mark visited cell\n",
    "\n",
    "        valid_actions = self.valid_actions()\n",
    "                \n",
    "        if not valid_actions:\n",
    "            nmode = 'blocked'\n",
    "        elif action in valid_actions:\n",
    "            nmode = 'valid'\n",
    "            if action == LEFT:\n",
    "                ncol -= 1\n",
    "            elif action == UP:\n",
    "                nrow -= 1\n",
    "            if action == RIGHT:\n",
    "                ncol += 1\n",
    "            elif action == DOWN:\n",
    "                nrow += 1\n",
    "        else:                  # invalid action, no change in rat position\n",
    "            mode = 'invalid'\n",
    "\n",
    "        # new state\n",
    "        self.state = (nrow, ncol, nmode)\n",
    "\n",
    "    def get_reward(self):\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
    "            return 1.0\n",
    "        if mode == 'blocked':\n",
    "            return self.min_reward - 1\n",
    "        if (rat_row, rat_col) in self.visited:\n",
    "            return -0.25\n",
    "        if mode == 'invalid':\n",
    "            return -0.75\n",
    "        if mode == 'valid':\n",
    "            return -0.04\n",
    "\n",
    "    def act(self, action):\n",
    "        self.update_state(action)\n",
    "        reward = self.get_reward()\n",
    "        self.total_reward += reward\n",
    "        status = self.game_status()\n",
    "        envstate = self.observe()\n",
    "        return envstate, reward, status\n",
    "\n",
    "    def observe(self):\n",
    "        canvas = self.draw_env()\n",
    "        envstate = canvas.reshape((1, -1))\n",
    "        return envstate\n",
    "\n",
    "    def draw_env(self):\n",
    "        canvas = np.copy(self.maze)\n",
    "        nrows, ncols = self.maze.shape\n",
    "        # clear all visual marks\n",
    "        for r in range(nrows):\n",
    "            for c in range(ncols):\n",
    "                if canvas[r,c] > 0.0:\n",
    "                    canvas[r,c] = 1.0\n",
    "        # draw the rat\n",
    "        row, col, valid = self.state\n",
    "        canvas[row, col] = rat_mark\n",
    "        return canvas\n",
    "\n",
    "    def game_status(self):\n",
    "        if self.total_reward < self.min_reward:\n",
    "            return 'lose'\n",
    "        rat_row, rat_col, mode = self.state\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if rat_row == nrows-1 and rat_col == ncols-1:\n",
    "            return 'win'\n",
    "\n",
    "        return 'not_over'\n",
    "\n",
    "    def valid_actions(self, cell=None):\n",
    "        if cell is None:\n",
    "            row, col, mode = self.state\n",
    "        else:\n",
    "            row, col = cell\n",
    "        actions = [0, 1, 2, 3]\n",
    "        nrows, ncols = self.maze.shape\n",
    "        if row == 0:\n",
    "            actions.remove(1)\n",
    "        elif row == nrows-1:\n",
    "            actions.remove(3)\n",
    "\n",
    "        if col == 0:\n",
    "            actions.remove(0)\n",
    "        elif col == ncols-1:\n",
    "            actions.remove(2)\n",
    "\n",
    "        if row>0 and self.maze[row-1,col] == 0.0:\n",
    "            actions.remove(1)\n",
    "        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n",
    "            actions.remove(3)\n",
    "\n",
    "        if col>0 and self.maze[row,col-1] == 0.0:\n",
    "            actions.remove(0)\n",
    "        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n",
    "            actions.remove(2)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEgvv0QHAcqO"
   },
   "outputs": [],
   "source": [
    "def show(qmaze):\n",
    "    plt.grid('on')\n",
    "    nrows, ncols = qmaze.maze.shape\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
    "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    canvas = np.copy(qmaze.maze)\n",
    "    for row,col in qmaze.visited:\n",
    "        canvas[row,col] = 0.6\n",
    "    rat_row, rat_col, _ = qmaze.state\n",
    "    canvas[rat_row, rat_col] = 0.3   # rat cell\n",
    "    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n",
    "    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PTTplH_Am9F"
   },
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXYrCEK_EZ-U"
   },
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
    "    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
    "    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTO46kedArMF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward= -0.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e814ab4748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qmaze = Qmaze(maze)\n",
    "canvas, reward, game_over = qmaze.act(DOWN)\n",
    "print(\"reward=\", reward)\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QOkRblSA3IH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e814b20348>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qmaze.act(DOWN)  # move down\n",
    "qmaze.act(RIGHT)  # move right\n",
    "qmaze.act(RIGHT)  # move right\n",
    "qmaze.act(RIGHT)  # move right\n",
    "qmaze.act(UP)  # move up\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Qj1TKfnA9qu"
   },
   "outputs": [],
   "source": [
    "def play_game(model, qmaze, rat_cell):\n",
    "    qmaze.reset(rat_cell)\n",
    "    envstate = qmaze.observe()\n",
    "    while True:\n",
    "        prev_envstate = envstate\n",
    "        # get next action\n",
    "        q = model.predict(prev_envstate)\n",
    "        action = np.argmax(q[0])\n",
    "\n",
    "        # apply action, get rewards and new state\n",
    "        envstate, reward, game_status = qmaze.act(action)\n",
    "        if game_status == 'win':\n",
    "            return True\n",
    "        elif game_status == 'lose':\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zw53DdHQBKF0"
   },
   "outputs": [],
   "source": [
    "def completion_check(model, qmaze):\n",
    "    for cell in qmaze.free_cells:\n",
    "        if not qmaze.valid_actions(cell):\n",
    "            return False\n",
    "        if not play_game(model, qmaze, cell):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bm9WstgwBgjg"
   },
   "outputs": [],
   "source": [
    "class Experience(object):\n",
    "    def __init__(self, model, max_memory=100, discount=0.95):\n",
    "        self.model = model\n",
    "        self.max_memory = max_memory\n",
    "        self.discount = discount\n",
    "        self.memory = list()\n",
    "        self.num_actions = model.output_shape[-1]\n",
    "\n",
    "    def remember(self, episode):\n",
    "        # episode = [envstate, action, reward, envstate_next, game_over]\n",
    "        # memory[i] = episode\n",
    "        # envstate == flattened 1d maze cells info, including rat cell (see method: observe)\n",
    "        self.memory.append(episode)\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def predict(self, envstate):\n",
    "        return self.model.predict(envstate)[0]\n",
    "\n",
    "    def get_data(self, data_size=10):\n",
    "        env_size = self.memory[0][0].shape[1]   # envstate 1d size (1st element of episode)\n",
    "        mem_size = len(self.memory)\n",
    "        data_size = min(mem_size, data_size)\n",
    "        inputs = np.zeros((data_size, env_size))\n",
    "        targets = np.zeros((data_size, self.num_actions))\n",
    "        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n",
    "            envstate, action, reward, envstate_next, game_over = self.memory[j]\n",
    "            inputs[i] = envstate\n",
    "            # There should be no target values for actions not taken.\n",
    "            targets[i] = self.predict(envstate)\n",
    "            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n",
    "            Q_sa = np.max(self.predict(envstate_next))\n",
    "            if game_over:\n",
    "                targets[i, action] = reward\n",
    "            else:\n",
    "                # reward + gamma * max_a' Q(s', a')\n",
    "                targets[i, action] = reward + self.discount * Q_sa\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QvK92JaBiL7"
   },
   "outputs": [],
   "source": [
    "def qtrain(model, maze, **opt):\n",
    "    global epsilon\n",
    "    n_epoch = opt.get('n_epoch', 15000)\n",
    "    max_memory = opt.get('max_memory', 1000)\n",
    "    data_size = opt.get('data_size', 50)\n",
    "    weights_file = opt.get('weights_file', \"\")\n",
    "    name = opt.get('name', 'model')\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # If you want to continue training from a previous model,\n",
    "    # just supply the h5 file name to weights_file option\n",
    "    if weights_file:\n",
    "        print(\"loading weights from file: %s\" % (weights_file,))\n",
    "        model.load_weights(weights_file)\n",
    "\n",
    "    # Construct environment/game from numpy array: maze (see above)\n",
    "    qmaze = Qmaze(maze)\n",
    "\n",
    "    # Initialize experience replay object\n",
    "    experience = Experience(model, max_memory=max_memory)\n",
    "\n",
    "    win_history = []   # history of win/lose game\n",
    "    n_free_cells = len(qmaze.free_cells)\n",
    "    hsize = qmaze.maze.size//2   # history window size\n",
    "    win_rate = 0.0\n",
    "    imctr = 1\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        loss = 0.0\n",
    "        rat_cell = random.choice(qmaze.free_cells)\n",
    "        qmaze.reset(rat_cell)\n",
    "        game_over = False\n",
    "\n",
    "        # get initial envstate (1d flattened canvas)\n",
    "        envstate = qmaze.observe()\n",
    "\n",
    "        n_episodes = 0\n",
    "        while not game_over:\n",
    "            valid_actions = qmaze.valid_actions()\n",
    "            if not valid_actions: break\n",
    "            prev_envstate = envstate\n",
    "            # Get next action\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                action = np.argmax(experience.predict(prev_envstate))\n",
    "\n",
    "            # Apply action, get reward and new envstate\n",
    "            envstate, reward, game_status = qmaze.act(action)\n",
    "            if game_status == 'win':\n",
    "                win_history.append(1)\n",
    "                game_over = True\n",
    "            elif game_status == 'lose':\n",
    "                win_history.append(0)\n",
    "                game_over = True\n",
    "            else:\n",
    "                game_over = False\n",
    "\n",
    "            # Store episode (experience)\n",
    "            episode = [prev_envstate, action, reward, envstate, game_over]\n",
    "            experience.remember(episode)\n",
    "            n_episodes += 1\n",
    "\n",
    "            # Train neural network model\n",
    "            inputs, targets = experience.get_data(data_size=data_size)\n",
    "            h = model.fit(\n",
    "                inputs,\n",
    "                targets,\n",
    "                epochs=8,\n",
    "                batch_size=16,\n",
    "                verbose=0,\n",
    "            )\n",
    "            loss = model.evaluate(inputs, targets, verbose=0)\n",
    "\n",
    "        if len(win_history) > hsize:\n",
    "            win_rate = sum(win_history[-hsize:]) / hsize\n",
    "    \n",
    "        dt = datetime.datetime.now() - start_time\n",
    "        t = format_time(dt.total_seconds())\n",
    "        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n",
    "        print(template.format(epoch, n_epoch-1, loss, n_episodes, sum(win_history), win_rate, t))\n",
    "        # we simply check if training has exhausted all free cells and if in all\n",
    "        # cases the agent won\n",
    "        if win_rate > 0.9 : epsilon = 0.05\n",
    "        if sum(win_history[-hsize:]) == hsize and completion_check(model, qmaze):\n",
    "            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n",
    "            break\n",
    "\n",
    "    # Save trained model weights and architecture, this will be used by the visualization code\n",
    "    h5file = name + \".h5\"\n",
    "    json_file = name + \".json\"\n",
    "    model.save_weights(h5file, overwrite=True)\n",
    "    with open(json_file, \"w\") as outfile:\n",
    "        json.dump(model.to_json(), outfile)\n",
    "    end_time = datetime.datetime.now()\n",
    "    dt = datetime.datetime.now() - start_time\n",
    "    seconds = dt.total_seconds()\n",
    "    t = format_time(seconds)\n",
    "    print('files: %s, %s' % (h5file, json_file))\n",
    "    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" % (epoch, max_memory, data_size, t))\n",
    "    return seconds\n",
    "\n",
    "# This is a small utility for printing readable time strings:\n",
    "def format_time(seconds):\n",
    "    if seconds < 400:\n",
    "        s = float(seconds)\n",
    "        return \"%.1f seconds\" % (s,)\n",
    "    elif seconds < 4000:\n",
    "        m = seconds / 60.0\n",
    "        return \"%.2f minutes\" % (m,)\n",
    "    else:\n",
    "        h = seconds / 3600.0\n",
    "        return \"%.2f hours\" % (h,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7W6tHgyyBzrr"
   },
   "outputs": [],
   "source": [
    "def build_model(maze, lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(maze.size, input_shape=(maze.size,)))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dense(maze.size))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dense(num_actions))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUWPPKi6B5tj"
   },
   "outputs": [],
   "source": [
    "maze =  np.array([\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n",
    "    [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n",
    "    [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n",
    "    [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n",
    "])\n",
    "\n",
    "qmaze = Qmaze(maze)\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sXIvaUxDE2tE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e814bf0f88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAGK0lEQVR4nO3dsWqU6RvG4ef7IwrR1eYPgzKlMAcwaYXY2XkU7gkkrWcwR7BHkN4DmO8AJoVlOsGACJZaWXxbxLBbJGsG39fMnVwXTJXl5iXZX1abZ4dpmgrYff+76QcA1yNWCCFWCCFWCCFWCCFWCHFvm3/4/v37097eXtMHPH78uD5+/Nh0s6rq6dOn9ezZs+a73759q4cPH0bsJr01bbfXWz98+FBfvnwZLvvaVrHu7e3Vixcv2rzqh9evX9ebN2+ablZVHR4e1uHhYfPdcRzr4OAgYjfprWm7vd66v79/5df8MRhCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCbHWD6fnz5/Xu3bumDxjHsXr8/3bGcWy+mWgYLr299UtWq1WX+0P8t+FnoQzD8GdV/VlVNZvNlsfHx00f8PXr13r06FHTTbv/bJ6enjbdrKqaz+c1m82a76Z9b3u89ejoqDabzeW/YadpuvZnuVxOra3X6+abdv/ZrKrmn9Vq1fytF+9N2e311h+NXdqfv7NCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCLFCCAfTbvGug2n9dh1Ms9t8sxxMczAN+L3ECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiG2ivXk5KSGYWj66bF5sdtDz/f22Lzqns+vfJbLZdTP7LbY6rrhkydPlm/fvm36gPl8XmdnZ003L3Z7XOD7/Plzt/e23u15hfCuX03c+euG1elSXq/dHnq+N+V74Gqi64bAfxArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhBArhNgq1uVy2eVSXuvNi90eF/h6vZdzSZcjf/v35mf/ovz7uuFsNlseHx83fUCvK3G9LvAtFosu7+1xNTHxuuFdvxzZ7Lrhj8trTfW6EtfrAl+v97pu2PfSZcr31nVDuAXECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHu3fQDyDR1uMg4jmPM7jiOTfeuw3XDLblu2PdnlrLb662uG7pu2FTPn1nKbq+3um4It4BYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIYRYIcStPph213eT3pq262Ca3Z3ftNtvc5ocTINbQawQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQwnXDW7zb862np6fNd+fzeZ2dnUXs9nrr0dFRTdPkuuFd2+351qpq/lmtVjG7vd56nqTrhhBNrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBiJ2IdhqH55+Tk5M7v9nzrVXeCfuWzXC5jdnu+9cpOph24bnjXL+X12u351tls1nzX5cjz64abzWZ3rxtWyEW7tN2eb+3B5chp+tGY64aQTKwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQQqwQ4t5NP6Dq/A5Ua+M43vndnm/tZRguvxX2K9brdfPNqqpPnz413/z+/fuVX9uJ64YpF+3SdpPeerHb49LlYrHo8r198OBB082q8+uG79+/v/Q31k9j/bf9/f1ps9k0e1jV+W/pg4ODppt2+2323n358mXz3fV63eV7u1gsmm5WVb169erKWP2dFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUKIFUJsdTCtqhZV1fqi1f+r6kvjTbv9Nu3226yqWkzT9MdlX9jqYFoPwzBspmnat9t+N+mtabs38VZ/DIYQYoUQuxDrX3a77Sa9NW33t7/1xv/OClzPLvyXFbgGsUIIsUIIsUIIsUKIvwGGzxFres8nOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze2 = np.array([\n",
    "    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.],\n",
    "    [ 1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
    "    [ 1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.],\n",
    "    [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  1.]\n",
    "])\n",
    "qmaze = Qmaze(maze)\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wK9lCeTACAcy",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0714 17:11:02.417086  6520 deprecation_wrapper.py:119] From D:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/14999 | Loss: 0.0475 | Episodes: 51 | Win count: 1 | Win rate: 0.000 | time: 4.8 seconds\n",
      "Epoch: 001/14999 | Loss: 0.0020 | Episodes: 232 | Win count: 1 | Win rate: 0.000 | time: 22.0 seconds\n",
      "Epoch: 002/14999 | Loss: 0.0030 | Episodes: 213 | Win count: 1 | Win rate: 0.000 | time: 37.4 seconds\n",
      "Epoch: 003/14999 | Loss: 0.0018 | Episodes: 222 | Win count: 1 | Win rate: 0.000 | time: 53.4 seconds\n",
      "Epoch: 004/14999 | Loss: 0.0053 | Episodes: 203 | Win count: 2 | Win rate: 0.000 | time: 68.2 seconds\n",
      "Epoch: 005/14999 | Loss: 0.0012 | Episodes: 38 | Win count: 3 | Win rate: 0.000 | time: 70.9 seconds\n",
      "Epoch: 006/14999 | Loss: 0.0044 | Episodes: 213 | Win count: 3 | Win rate: 0.000 | time: 86.4 seconds\n",
      "Epoch: 007/14999 | Loss: 0.0024 | Episodes: 1 | Win count: 4 | Win rate: 0.000 | time: 86.5 seconds\n",
      "Epoch: 008/14999 | Loss: 0.0020 | Episodes: 222 | Win count: 4 | Win rate: 0.000 | time: 102.6 seconds\n",
      "Epoch: 009/14999 | Loss: 0.0076 | Episodes: 222 | Win count: 4 | Win rate: 0.000 | time: 118.7 seconds\n",
      "Epoch: 010/14999 | Loss: 0.1475 | Episodes: 3 | Win count: 5 | Win rate: 0.000 | time: 118.9 seconds\n",
      "Epoch: 011/14999 | Loss: 0.0028 | Episodes: 223 | Win count: 5 | Win rate: 0.000 | time: 135.0 seconds\n",
      "Epoch: 012/14999 | Loss: 0.0027 | Episodes: 213 | Win count: 5 | Win rate: 0.000 | time: 150.4 seconds\n",
      "Epoch: 013/14999 | Loss: 0.0011 | Episodes: 221 | Win count: 5 | Win rate: 0.000 | time: 166.3 seconds\n",
      "Epoch: 014/14999 | Loss: 0.0453 | Episodes: 219 | Win count: 5 | Win rate: 0.000 | time: 182.2 seconds\n",
      "Epoch: 015/14999 | Loss: 0.0658 | Episodes: 144 | Win count: 6 | Win rate: 0.000 | time: 192.6 seconds\n",
      "Epoch: 016/14999 | Loss: 0.0613 | Episodes: 5 | Win count: 7 | Win rate: 0.000 | time: 193.0 seconds\n",
      "Epoch: 017/14999 | Loss: 0.0682 | Episodes: 202 | Win count: 7 | Win rate: 0.000 | time: 207.6 seconds\n",
      "Epoch: 018/14999 | Loss: 0.0063 | Episodes: 221 | Win count: 7 | Win rate: 0.000 | time: 223.7 seconds\n",
      "Epoch: 019/14999 | Loss: 0.0025 | Episodes: 223 | Win count: 7 | Win rate: 0.000 | time: 239.9 seconds\n",
      "Epoch: 020/14999 | Loss: 0.0015 | Episodes: 1 | Win count: 8 | Win rate: 0.000 | time: 239.9 seconds\n",
      "Epoch: 021/14999 | Loss: 0.0017 | Episodes: 2 | Win count: 9 | Win rate: 0.000 | time: 240.1 seconds\n",
      "Epoch: 022/14999 | Loss: 0.0010 | Episodes: 220 | Win count: 9 | Win rate: 0.000 | time: 256.1 seconds\n",
      "Epoch: 023/14999 | Loss: 0.0013 | Episodes: 11 | Win count: 10 | Win rate: 0.000 | time: 256.9 seconds\n",
      "Epoch: 024/14999 | Loss: 0.0831 | Episodes: 213 | Win count: 10 | Win rate: 0.000 | time: 272.3 seconds\n",
      "Epoch: 025/14999 | Loss: 0.0028 | Episodes: 222 | Win count: 10 | Win rate: 0.000 | time: 288.4 seconds\n",
      "Epoch: 026/14999 | Loss: 0.0036 | Episodes: 216 | Win count: 10 | Win rate: 0.000 | time: 304.1 seconds\n",
      "Epoch: 027/14999 | Loss: 0.0013 | Episodes: 216 | Win count: 10 | Win rate: 0.000 | time: 319.9 seconds\n",
      "Epoch: 028/14999 | Loss: 0.0015 | Episodes: 211 | Win count: 10 | Win rate: 0.000 | time: 335.1 seconds\n",
      "Epoch: 029/14999 | Loss: 0.0268 | Episodes: 44 | Win count: 11 | Win rate: 0.000 | time: 338.3 seconds\n",
      "Epoch: 030/14999 | Loss: 0.0573 | Episodes: 223 | Win count: 11 | Win rate: 0.000 | time: 354.4 seconds\n",
      "Epoch: 031/14999 | Loss: 0.0006 | Episodes: 209 | Win count: 11 | Win rate: 0.000 | time: 369.5 seconds\n",
      "Epoch: 032/14999 | Loss: 0.0031 | Episodes: 4 | Win count: 12 | Win rate: 0.000 | time: 369.8 seconds\n",
      "Epoch: 033/14999 | Loss: 0.0038 | Episodes: 224 | Win count: 12 | Win rate: 0.000 | time: 386.1 seconds\n",
      "Epoch: 034/14999 | Loss: 0.0011 | Episodes: 212 | Win count: 12 | Win rate: 0.000 | time: 6.70 minutes\n",
      "Epoch: 035/14999 | Loss: 0.0013 | Episodes: 216 | Win count: 12 | Win rate: 0.000 | time: 6.97 minutes\n",
      "Epoch: 036/14999 | Loss: 0.0711 | Episodes: 45 | Win count: 13 | Win rate: 0.000 | time: 7.03 minutes\n",
      "Epoch: 037/14999 | Loss: 0.0647 | Episodes: 231 | Win count: 13 | Win rate: 0.000 | time: 7.36 minutes\n",
      "Epoch: 038/14999 | Loss: 0.0079 | Episodes: 226 | Win count: 13 | Win rate: 0.000 | time: 7.64 minutes\n",
      "Epoch: 039/14999 | Loss: 0.0021 | Episodes: 225 | Win count: 13 | Win rate: 0.000 | time: 7.92 minutes\n",
      "Epoch: 040/14999 | Loss: 0.0014 | Episodes: 211 | Win count: 13 | Win rate: 0.000 | time: 8.18 minutes\n",
      "Epoch: 041/14999 | Loss: 0.0015 | Episodes: 220 | Win count: 13 | Win rate: 0.000 | time: 8.45 minutes\n",
      "Epoch: 042/14999 | Loss: 0.0017 | Episodes: 217 | Win count: 13 | Win rate: 0.000 | time: 8.73 minutes\n",
      "Epoch: 043/14999 | Loss: 0.0013 | Episodes: 229 | Win count: 13 | Win rate: 0.000 | time: 9.03 minutes\n",
      "Epoch: 044/14999 | Loss: 0.0022 | Episodes: 220 | Win count: 13 | Win rate: 0.000 | time: 9.29 minutes\n",
      "Epoch: 045/14999 | Loss: 0.0900 | Episodes: 213 | Win count: 13 | Win rate: 0.000 | time: 9.56 minutes\n",
      "Epoch: 046/14999 | Loss: 0.0012 | Episodes: 223 | Win count: 13 | Win rate: 0.000 | time: 9.86 minutes\n",
      "Epoch: 047/14999 | Loss: 0.0007 | Episodes: 225 | Win count: 13 | Win rate: 0.000 | time: 10.16 minutes\n",
      "Epoch: 048/14999 | Loss: 0.0012 | Episodes: 221 | Win count: 13 | Win rate: 0.000 | time: 10.45 minutes\n",
      "Epoch: 049/14999 | Loss: 0.0022 | Episodes: 226 | Win count: 13 | Win rate: 0.000 | time: 10.72 minutes\n",
      "Epoch: 050/14999 | Loss: 0.0007 | Episodes: 9 | Win count: 14 | Win rate: 0.260 | time: 10.73 minutes\n",
      "Epoch: 051/14999 | Loss: 0.0031 | Episodes: 222 | Win count: 14 | Win rate: 0.260 | time: 11.01 minutes\n",
      "Epoch: 052/14999 | Loss: 0.0077 | Episodes: 11 | Win count: 15 | Win rate: 0.280 | time: 11.03 minutes\n",
      "Epoch: 053/14999 | Loss: 0.0092 | Episodes: 219 | Win count: 15 | Win rate: 0.280 | time: 11.29 minutes\n",
      "Epoch: 054/14999 | Loss: 0.0011 | Episodes: 221 | Win count: 15 | Win rate: 0.260 | time: 11.55 minutes\n",
      "Epoch: 055/14999 | Loss: 0.0076 | Episodes: 235 | Win count: 15 | Win rate: 0.240 | time: 11.83 minutes\n",
      "Epoch: 056/14999 | Loss: 0.0010 | Episodes: 217 | Win count: 15 | Win rate: 0.240 | time: 12.12 minutes\n",
      "Epoch: 057/14999 | Loss: 0.0015 | Episodes: 231 | Win count: 15 | Win rate: 0.220 | time: 12.41 minutes\n",
      "Epoch: 058/14999 | Loss: 0.0018 | Episodes: 227 | Win count: 15 | Win rate: 0.220 | time: 12.68 minutes\n",
      "Epoch: 059/14999 | Loss: 0.0130 | Episodes: 10 | Win count: 16 | Win rate: 0.240 | time: 12.69 minutes\n",
      "Epoch: 060/14999 | Loss: 0.0017 | Episodes: 221 | Win count: 16 | Win rate: 0.220 | time: 12.96 minutes\n",
      "Epoch: 061/14999 | Loss: 0.0545 | Episodes: 12 | Win count: 17 | Win rate: 0.240 | time: 12.97 minutes\n",
      "Epoch: 062/14999 | Loss: 0.0822 | Episodes: 233 | Win count: 17 | Win rate: 0.240 | time: 13.25 minutes\n",
      "Epoch: 063/14999 | Loss: 0.0099 | Episodes: 72 | Win count: 18 | Win rate: 0.260 | time: 13.33 minutes\n",
      "Epoch: 064/14999 | Loss: 0.0022 | Episodes: 71 | Win count: 19 | Win rate: 0.280 | time: 13.42 minutes\n",
      "Epoch: 065/14999 | Loss: 0.0034 | Episodes: 37 | Win count: 20 | Win rate: 0.280 | time: 13.47 minutes\n",
      "Epoch: 066/14999 | Loss: 0.0315 | Episodes: 57 | Win count: 21 | Win rate: 0.280 | time: 13.54 minutes\n",
      "Epoch: 067/14999 | Loss: 0.0092 | Episodes: 219 | Win count: 21 | Win rate: 0.280 | time: 13.80 minutes\n",
      "Epoch: 068/14999 | Loss: 0.0039 | Episodes: 26 | Win count: 22 | Win rate: 0.300 | time: 13.83 minutes\n",
      "Epoch: 069/14999 | Loss: 0.0310 | Episodes: 34 | Win count: 23 | Win rate: 0.320 | time: 13.87 minutes\n",
      "Epoch: 070/14999 | Loss: 0.0027 | Episodes: 18 | Win count: 24 | Win rate: 0.320 | time: 13.90 minutes\n",
      "Epoch: 071/14999 | Loss: 0.0082 | Episodes: 23 | Win count: 25 | Win rate: 0.320 | time: 13.92 minutes\n",
      "Epoch: 072/14999 | Loss: 0.0019 | Episodes: 214 | Win count: 25 | Win rate: 0.320 | time: 14.19 minutes\n",
      "Epoch: 073/14999 | Loss: 0.0034 | Episodes: 11 | Win count: 26 | Win rate: 0.320 | time: 14.21 minutes\n",
      "Epoch: 074/14999 | Loss: 0.0019 | Episodes: 209 | Win count: 26 | Win rate: 0.320 | time: 14.47 minutes\n",
      "Epoch: 075/14999 | Loss: 0.0016 | Episodes: 213 | Win count: 27 | Win rate: 0.340 | time: 14.72 minutes\n",
      "Epoch: 076/14999 | Loss: 0.0029 | Episodes: 16 | Win count: 28 | Win rate: 0.360 | time: 14.74 minutes\n",
      "Epoch: 077/14999 | Loss: 0.0053 | Episodes: 3 | Win count: 29 | Win rate: 0.380 | time: 14.75 minutes\n",
      "Epoch: 078/14999 | Loss: 0.0063 | Episodes: 34 | Win count: 30 | Win rate: 0.400 | time: 14.79 minutes\n",
      "Epoch: 079/14999 | Loss: 0.0086 | Episodes: 35 | Win count: 31 | Win rate: 0.400 | time: 14.83 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 080/14999 | Loss: 0.0034 | Episodes: 216 | Win count: 31 | Win rate: 0.400 | time: 15.10 minutes\n",
      "Epoch: 081/14999 | Loss: 0.0033 | Episodes: 19 | Win count: 32 | Win rate: 0.420 | time: 15.12 minutes\n",
      "Epoch: 082/14999 | Loss: 0.0025 | Episodes: 36 | Win count: 33 | Win rate: 0.420 | time: 15.17 minutes\n",
      "Epoch: 083/14999 | Loss: 0.0080 | Episodes: 14 | Win count: 34 | Win rate: 0.440 | time: 15.18 minutes\n",
      "Epoch: 084/14999 | Loss: 0.0019 | Episodes: 30 | Win count: 35 | Win rate: 0.460 | time: 15.22 minutes\n",
      "Epoch: 085/14999 | Loss: 0.0022 | Episodes: 33 | Win count: 36 | Win rate: 0.480 | time: 15.26 minutes\n",
      "Epoch: 086/14999 | Loss: 0.0770 | Episodes: 17 | Win count: 37 | Win rate: 0.480 | time: 15.28 minutes\n",
      "Epoch: 087/14999 | Loss: 0.0014 | Episodes: 24 | Win count: 38 | Win rate: 0.500 | time: 15.31 minutes\n",
      "Epoch: 088/14999 | Loss: 0.0068 | Episodes: 220 | Win count: 38 | Win rate: 0.500 | time: 15.62 minutes\n",
      "Epoch: 089/14999 | Loss: 0.0067 | Episodes: 27 | Win count: 39 | Win rate: 0.520 | time: 15.65 minutes\n",
      "Epoch: 090/14999 | Loss: 0.0011 | Episodes: 211 | Win count: 39 | Win rate: 0.520 | time: 15.93 minutes\n",
      "Epoch: 091/14999 | Loss: 0.0073 | Episodes: 132 | Win count: 40 | Win rate: 0.540 | time: 16.11 minutes\n",
      "Epoch: 092/14999 | Loss: 0.0044 | Episodes: 13 | Win count: 41 | Win rate: 0.560 | time: 16.12 minutes\n",
      "Epoch: 093/14999 | Loss: 0.0044 | Episodes: 33 | Win count: 42 | Win rate: 0.580 | time: 16.17 minutes\n",
      "Epoch: 094/14999 | Loss: 0.0042 | Episodes: 37 | Win count: 43 | Win rate: 0.600 | time: 16.22 minutes\n",
      "Epoch: 095/14999 | Loss: 0.0045 | Episodes: 32 | Win count: 44 | Win rate: 0.620 | time: 16.26 minutes\n",
      "Epoch: 096/14999 | Loss: 0.0024 | Episodes: 37 | Win count: 45 | Win rate: 0.640 | time: 16.30 minutes\n",
      "Epoch: 097/14999 | Loss: 0.0025 | Episodes: 83 | Win count: 46 | Win rate: 0.660 | time: 16.41 minutes\n",
      "Epoch: 098/14999 | Loss: 0.0084 | Episodes: 25 | Win count: 47 | Win rate: 0.680 | time: 16.45 minutes\n",
      "Epoch: 099/14999 | Loss: 0.0027 | Episodes: 57 | Win count: 48 | Win rate: 0.700 | time: 16.52 minutes\n",
      "Epoch: 100/14999 | Loss: 0.0034 | Episodes: 26 | Win count: 49 | Win rate: 0.700 | time: 16.55 minutes\n",
      "Epoch: 101/14999 | Loss: 0.0047 | Episodes: 31 | Win count: 50 | Win rate: 0.720 | time: 16.59 minutes\n",
      "Epoch: 102/14999 | Loss: 0.0037 | Episodes: 32 | Win count: 51 | Win rate: 0.720 | time: 16.63 minutes\n",
      "Epoch: 103/14999 | Loss: 0.0011 | Episodes: 32 | Win count: 52 | Win rate: 0.740 | time: 16.68 minutes\n",
      "Epoch: 104/14999 | Loss: 0.0028 | Episodes: 42 | Win count: 53 | Win rate: 0.760 | time: 16.73 minutes\n",
      "Epoch: 105/14999 | Loss: 0.0012 | Episodes: 20 | Win count: 54 | Win rate: 0.780 | time: 16.76 minutes\n",
      "Epoch: 106/14999 | Loss: 0.0014 | Episodes: 5 | Win count: 55 | Win rate: 0.800 | time: 16.76 minutes\n",
      "Epoch: 107/14999 | Loss: 0.0012 | Episodes: 13 | Win count: 56 | Win rate: 0.820 | time: 16.78 minutes\n",
      "Epoch: 108/14999 | Loss: 0.0015 | Episodes: 30 | Win count: 57 | Win rate: 0.840 | time: 16.82 minutes\n",
      "Epoch: 109/14999 | Loss: 0.0016 | Episodes: 7 | Win count: 58 | Win rate: 0.840 | time: 16.83 minutes\n",
      "Epoch: 110/14999 | Loss: 0.0009 | Episodes: 7 | Win count: 59 | Win rate: 0.860 | time: 16.83 minutes\n",
      "Epoch: 111/14999 | Loss: 0.0016 | Episodes: 28 | Win count: 60 | Win rate: 0.860 | time: 16.87 minutes\n",
      "Epoch: 112/14999 | Loss: 0.0121 | Episodes: 15 | Win count: 61 | Win rate: 0.880 | time: 16.89 minutes\n",
      "Epoch: 113/14999 | Loss: 0.0020 | Episodes: 23 | Win count: 62 | Win rate: 0.880 | time: 16.92 minutes\n",
      "Epoch: 114/14999 | Loss: 0.0008 | Episodes: 40 | Win count: 63 | Win rate: 0.880 | time: 16.97 minutes\n",
      "Epoch: 115/14999 | Loss: 0.0007 | Episodes: 36 | Win count: 64 | Win rate: 0.880 | time: 17.01 minutes\n",
      "Epoch: 116/14999 | Loss: 0.0019 | Episodes: 24 | Win count: 65 | Win rate: 0.880 | time: 17.04 minutes\n",
      "Epoch: 117/14999 | Loss: 0.0009 | Episodes: 4 | Win count: 66 | Win rate: 0.900 | time: 17.05 minutes\n",
      "Epoch: 118/14999 | Loss: 0.0024 | Episodes: 15 | Win count: 67 | Win rate: 0.900 | time: 17.07 minutes\n",
      "Epoch: 119/14999 | Loss: 0.0020 | Episodes: 5 | Win count: 68 | Win rate: 0.900 | time: 17.08 minutes\n",
      "Epoch: 120/14999 | Loss: 0.0014 | Episodes: 16 | Win count: 69 | Win rate: 0.900 | time: 17.10 minutes\n",
      "Epoch: 121/14999 | Loss: 0.0016 | Episodes: 27 | Win count: 70 | Win rate: 0.900 | time: 17.13 minutes\n",
      "Epoch: 122/14999 | Loss: 0.0008 | Episodes: 16 | Win count: 71 | Win rate: 0.920 | time: 17.15 minutes\n",
      "Epoch: 123/14999 | Loss: 0.0007 | Episodes: 15 | Win count: 72 | Win rate: 0.920 | time: 17.17 minutes\n",
      "Epoch: 124/14999 | Loss: 0.0002 | Episodes: 11 | Win count: 73 | Win rate: 0.940 | time: 17.19 minutes\n",
      "Epoch: 125/14999 | Loss: 0.0012 | Episodes: 14 | Win count: 74 | Win rate: 0.940 | time: 17.20 minutes\n",
      "Epoch: 126/14999 | Loss: 0.0012 | Episodes: 40 | Win count: 75 | Win rate: 0.940 | time: 17.26 minutes\n",
      "Epoch: 127/14999 | Loss: 0.0010 | Episodes: 49 | Win count: 76 | Win rate: 0.940 | time: 17.32 minutes\n",
      "Epoch: 128/14999 | Loss: 0.0001 | Episodes: 13 | Win count: 77 | Win rate: 0.940 | time: 17.34 minutes\n",
      "Epoch: 129/14999 | Loss: 0.0002 | Episodes: 15 | Win count: 78 | Win rate: 0.940 | time: 17.36 minutes\n",
      "Epoch: 130/14999 | Loss: 0.0025 | Episodes: 52 | Win count: 79 | Win rate: 0.960 | time: 17.42 minutes\n",
      "Epoch: 131/14999 | Loss: 0.0015 | Episodes: 22 | Win count: 80 | Win rate: 0.960 | time: 17.45 minutes\n",
      "Epoch: 132/14999 | Loss: 0.0007 | Episodes: 16 | Win count: 81 | Win rate: 0.960 | time: 17.47 minutes\n",
      "Epoch: 133/14999 | Loss: 0.0005 | Episodes: 17 | Win count: 82 | Win rate: 0.960 | time: 17.49 minutes\n",
      "Epoch: 134/14999 | Loss: 0.0006 | Episodes: 34 | Win count: 83 | Win rate: 0.960 | time: 17.53 minutes\n",
      "Epoch: 135/14999 | Loss: 0.0013 | Episodes: 27 | Win count: 84 | Win rate: 0.960 | time: 17.57 minutes\n",
      "Epoch: 136/14999 | Loss: 0.0006 | Episodes: 29 | Win count: 85 | Win rate: 0.960 | time: 17.60 minutes\n",
      "Epoch: 137/14999 | Loss: 0.0011 | Episodes: 60 | Win count: 86 | Win rate: 0.960 | time: 17.68 minutes\n",
      "Epoch: 138/14999 | Loss: 0.0008 | Episodes: 29 | Win count: 87 | Win rate: 0.980 | time: 17.72 minutes\n",
      "Epoch: 139/14999 | Loss: 0.0000 | Episodes: 26 | Win count: 88 | Win rate: 0.980 | time: 17.76 minutes\n",
      "Epoch: 140/14999 | Loss: 0.0003 | Episodes: 17 | Win count: 89 | Win rate: 1.000 | time: 17.78 minutes\n",
      "Epoch: 141/14999 | Loss: 0.0003 | Episodes: 22 | Win count: 90 | Win rate: 1.000 | time: 17.81 minutes\n",
      "Epoch: 142/14999 | Loss: 0.0003 | Episodes: 18 | Win count: 91 | Win rate: 1.000 | time: 17.83 minutes\n",
      "Epoch: 143/14999 | Loss: 0.0005 | Episodes: 20 | Win count: 92 | Win rate: 1.000 | time: 17.86 minutes\n",
      "Epoch: 144/14999 | Loss: 0.0008 | Episodes: 42 | Win count: 93 | Win rate: 1.000 | time: 17.91 minutes\n",
      "Epoch: 145/14999 | Loss: 0.0026 | Episodes: 20 | Win count: 94 | Win rate: 1.000 | time: 17.94 minutes\n",
      "Epoch: 146/14999 | Loss: 0.0010 | Episodes: 12 | Win count: 95 | Win rate: 1.000 | time: 17.96 minutes\n",
      "Epoch: 147/14999 | Loss: 0.0010 | Episodes: 19 | Win count: 96 | Win rate: 1.000 | time: 17.98 minutes\n",
      "Epoch: 148/14999 | Loss: 0.0028 | Episodes: 23 | Win count: 97 | Win rate: 1.000 | time: 18.01 minutes\n",
      "Epoch: 149/14999 | Loss: 0.0001 | Episodes: 23 | Win count: 98 | Win rate: 1.000 | time: 18.04 minutes\n",
      "Epoch: 150/14999 | Loss: 0.0009 | Episodes: 45 | Win count: 99 | Win rate: 1.000 | time: 18.10 minutes\n",
      "Epoch: 151/14999 | Loss: 0.0005 | Episodes: 19 | Win count: 100 | Win rate: 1.000 | time: 18.13 minutes\n",
      "Epoch: 152/14999 | Loss: 0.0002 | Episodes: 24 | Win count: 101 | Win rate: 1.000 | time: 18.16 minutes\n",
      "Epoch: 153/14999 | Loss: 0.0006 | Episodes: 9 | Win count: 102 | Win rate: 1.000 | time: 18.17 minutes\n",
      "Epoch: 154/14999 | Loss: 0.0002 | Episodes: 12 | Win count: 103 | Win rate: 1.000 | time: 18.20 minutes\n",
      "Epoch: 155/14999 | Loss: 0.0003 | Episodes: 16 | Win count: 104 | Win rate: 1.000 | time: 18.22 minutes\n",
      "Epoch: 156/14999 | Loss: 0.0009 | Episodes: 25 | Win count: 105 | Win rate: 1.000 | time: 18.25 minutes\n",
      "Epoch: 157/14999 | Loss: 0.0003 | Episodes: 20 | Win count: 106 | Win rate: 1.000 | time: 18.28 minutes\n",
      "Epoch: 158/14999 | Loss: 0.0022 | Episodes: 18 | Win count: 107 | Win rate: 1.000 | time: 18.30 minutes\n",
      "Epoch: 159/14999 | Loss: 0.0002 | Episodes: 16 | Win count: 108 | Win rate: 1.000 | time: 18.32 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160/14999 | Loss: 0.0014 | Episodes: 28 | Win count: 109 | Win rate: 1.000 | time: 18.36 minutes\n",
      "Epoch: 161/14999 | Loss: 0.0003 | Episodes: 19 | Win count: 110 | Win rate: 1.000 | time: 18.39 minutes\n",
      "Epoch: 162/14999 | Loss: 0.0002 | Episodes: 18 | Win count: 111 | Win rate: 1.000 | time: 18.41 minutes\n",
      "Epoch: 163/14999 | Loss: 0.0004 | Episodes: 29 | Win count: 112 | Win rate: 1.000 | time: 18.45 minutes\n",
      "Epoch: 164/14999 | Loss: 0.0004 | Episodes: 24 | Win count: 113 | Win rate: 1.000 | time: 18.48 minutes\n",
      "Epoch: 165/14999 | Loss: 0.0009 | Episodes: 56 | Win count: 114 | Win rate: 1.000 | time: 18.55 minutes\n",
      "Epoch: 166/14999 | Loss: 0.0007 | Episodes: 11 | Win count: 115 | Win rate: 1.000 | time: 18.56 minutes\n",
      "Epoch: 167/14999 | Loss: 0.0010 | Episodes: 39 | Win count: 116 | Win rate: 1.000 | time: 18.61 minutes\n",
      "Epoch: 168/14999 | Loss: 0.0009 | Episodes: 23 | Win count: 117 | Win rate: 1.000 | time: 18.64 minutes\n",
      "Epoch: 169/14999 | Loss: 0.0007 | Episodes: 54 | Win count: 118 | Win rate: 1.000 | time: 18.71 minutes\n",
      "Epoch: 170/14999 | Loss: 0.0007 | Episodes: 4 | Win count: 119 | Win rate: 1.000 | time: 18.72 minutes\n",
      "Epoch: 171/14999 | Loss: 0.0005 | Episodes: 24 | Win count: 120 | Win rate: 1.000 | time: 18.75 minutes\n",
      "Epoch: 172/14999 | Loss: 0.0008 | Episodes: 25 | Win count: 121 | Win rate: 1.000 | time: 18.78 minutes\n",
      "Epoch: 173/14999 | Loss: 0.0004 | Episodes: 32 | Win count: 122 | Win rate: 1.000 | time: 18.82 minutes\n",
      "Epoch: 174/14999 | Loss: 0.0006 | Episodes: 39 | Win count: 123 | Win rate: 1.000 | time: 18.87 minutes\n",
      "Epoch: 175/14999 | Loss: 0.0006 | Episodes: 43 | Win count: 124 | Win rate: 1.000 | time: 18.92 minutes\n",
      "Epoch: 176/14999 | Loss: 0.0003 | Episodes: 22 | Win count: 125 | Win rate: 1.000 | time: 18.95 minutes\n",
      "Epoch: 177/14999 | Loss: 0.0003 | Episodes: 43 | Win count: 126 | Win rate: 1.000 | time: 19.01 minutes\n",
      "Epoch: 178/14999 | Loss: 0.0008 | Episodes: 64 | Win count: 127 | Win rate: 1.000 | time: 19.09 minutes\n",
      "Epoch: 179/14999 | Loss: 0.0008 | Episodes: 17 | Win count: 128 | Win rate: 1.000 | time: 19.11 minutes\n",
      "Epoch: 180/14999 | Loss: 0.0009 | Episodes: 27 | Win count: 129 | Win rate: 1.000 | time: 19.15 minutes\n",
      "Epoch: 181/14999 | Loss: 0.0009 | Episodes: 59 | Win count: 130 | Win rate: 1.000 | time: 19.22 minutes\n",
      "Epoch: 182/14999 | Loss: 0.0006 | Episodes: 43 | Win count: 131 | Win rate: 1.000 | time: 19.28 minutes\n",
      "Epoch: 183/14999 | Loss: 0.0015 | Episodes: 7 | Win count: 132 | Win rate: 1.000 | time: 19.29 minutes\n",
      "Epoch: 184/14999 | Loss: 0.0003 | Episodes: 18 | Win count: 133 | Win rate: 1.000 | time: 19.31 minutes\n",
      "Epoch: 185/14999 | Loss: 0.0005 | Episodes: 24 | Win count: 134 | Win rate: 1.000 | time: 19.34 minutes\n",
      "Epoch: 186/14999 | Loss: 0.0004 | Episodes: 36 | Win count: 135 | Win rate: 1.000 | time: 19.39 minutes\n",
      "Epoch: 187/14999 | Loss: 0.0008 | Episodes: 25 | Win count: 136 | Win rate: 1.000 | time: 19.42 minutes\n",
      "Epoch: 188/14999 | Loss: 0.0005 | Episodes: 13 | Win count: 137 | Win rate: 1.000 | time: 19.44 minutes\n",
      "Epoch: 189/14999 | Loss: 0.0009 | Episodes: 19 | Win count: 138 | Win rate: 1.000 | time: 19.46 minutes\n",
      "Epoch: 190/14999 | Loss: 0.0007 | Episodes: 22 | Win count: 139 | Win rate: 1.000 | time: 19.49 minutes\n",
      "Epoch: 191/14999 | Loss: 0.0004 | Episodes: 37 | Win count: 140 | Win rate: 1.000 | time: 19.54 minutes\n",
      "Epoch: 192/14999 | Loss: 0.0005 | Episodes: 34 | Win count: 141 | Win rate: 1.000 | time: 19.58 minutes\n",
      "Epoch: 193/14999 | Loss: 0.0005 | Episodes: 14 | Win count: 142 | Win rate: 1.000 | time: 19.60 minutes\n",
      "Epoch: 194/14999 | Loss: 0.0005 | Episodes: 47 | Win count: 143 | Win rate: 1.000 | time: 19.66 minutes\n",
      "Epoch: 195/14999 | Loss: 0.0005 | Episodes: 21 | Win count: 144 | Win rate: 1.000 | time: 19.69 minutes\n",
      "Epoch: 196/14999 | Loss: 0.0002 | Episodes: 23 | Win count: 145 | Win rate: 1.000 | time: 19.72 minutes\n",
      "Epoch: 197/14999 | Loss: 0.0001 | Episodes: 28 | Win count: 146 | Win rate: 1.000 | time: 19.76 minutes\n",
      "Epoch: 198/14999 | Loss: 0.0006 | Episodes: 27 | Win count: 147 | Win rate: 1.000 | time: 19.79 minutes\n",
      "Epoch: 199/14999 | Loss: 0.0009 | Episodes: 44 | Win count: 148 | Win rate: 1.000 | time: 19.85 minutes\n",
      "Epoch: 200/14999 | Loss: 0.0010 | Episodes: 42 | Win count: 149 | Win rate: 1.000 | time: 19.90 minutes\n",
      "Epoch: 201/14999 | Loss: 0.0010 | Episodes: 23 | Win count: 150 | Win rate: 1.000 | time: 19.93 minutes\n",
      "Epoch: 202/14999 | Loss: 0.0012 | Episodes: 10 | Win count: 151 | Win rate: 1.000 | time: 19.94 minutes\n",
      "Epoch: 203/14999 | Loss: 0.0001 | Episodes: 21 | Win count: 152 | Win rate: 1.000 | time: 19.97 minutes\n",
      "Epoch: 204/14999 | Loss: 0.0011 | Episodes: 23 | Win count: 153 | Win rate: 1.000 | time: 20.00 minutes\n",
      "Epoch: 205/14999 | Loss: 0.0017 | Episodes: 25 | Win count: 154 | Win rate: 1.000 | time: 20.03 minutes\n",
      "Epoch: 206/14999 | Loss: 0.0011 | Episodes: 3 | Win count: 155 | Win rate: 1.000 | time: 20.04 minutes\n",
      "Epoch: 207/14999 | Loss: 0.0002 | Episodes: 32 | Win count: 156 | Win rate: 1.000 | time: 20.08 minutes\n",
      "Epoch: 208/14999 | Loss: 0.0005 | Episodes: 35 | Win count: 157 | Win rate: 1.000 | time: 20.12 minutes\n",
      "Epoch: 209/14999 | Loss: 0.0020 | Episodes: 41 | Win count: 158 | Win rate: 1.000 | time: 20.18 minutes\n",
      "Epoch: 210/14999 | Loss: 0.0004 | Episodes: 50 | Win count: 159 | Win rate: 1.000 | time: 20.24 minutes\n",
      "Epoch: 211/14999 | Loss: 0.0006 | Episodes: 38 | Win count: 160 | Win rate: 1.000 | time: 20.29 minutes\n",
      "Epoch: 212/14999 | Loss: 0.0001 | Episodes: 16 | Win count: 161 | Win rate: 1.000 | time: 20.31 minutes\n",
      "Epoch: 213/14999 | Loss: 0.0010 | Episodes: 18 | Win count: 162 | Win rate: 1.000 | time: 20.33 minutes\n",
      "Epoch: 214/14999 | Loss: 0.0017 | Episodes: 33 | Win count: 163 | Win rate: 1.000 | time: 20.37 minutes\n",
      "Epoch: 215/14999 | Loss: 0.0004 | Episodes: 23 | Win count: 164 | Win rate: 1.000 | time: 20.40 minutes\n",
      "Epoch: 216/14999 | Loss: 0.0002 | Episodes: 40 | Win count: 165 | Win rate: 1.000 | time: 20.46 minutes\n",
      "Epoch: 217/14999 | Loss: 0.0004 | Episodes: 41 | Win count: 166 | Win rate: 1.000 | time: 20.51 minutes\n",
      "Epoch: 218/14999 | Loss: 0.0003 | Episodes: 20 | Win count: 167 | Win rate: 1.000 | time: 20.53 minutes\n",
      "Epoch: 219/14999 | Loss: 0.0018 | Episodes: 15 | Win count: 168 | Win rate: 1.000 | time: 20.55 minutes\n",
      "Epoch: 220/14999 | Loss: 0.0004 | Episodes: 6 | Win count: 169 | Win rate: 1.000 | time: 20.56 minutes\n",
      "Epoch: 221/14999 | Loss: 0.0007 | Episodes: 5 | Win count: 170 | Win rate: 1.000 | time: 20.58 minutes\n",
      "Epoch: 222/14999 | Loss: 0.0006 | Episodes: 18 | Win count: 171 | Win rate: 1.000 | time: 20.60 minutes\n",
      "Epoch: 223/14999 | Loss: 0.0002 | Episodes: 48 | Win count: 172 | Win rate: 1.000 | time: 20.66 minutes\n",
      "Epoch: 224/14999 | Loss: 0.0019 | Episodes: 20 | Win count: 173 | Win rate: 1.000 | time: 20.69 minutes\n",
      "Reached 100% win rate at epoch: 224\n",
      "files: model.h5, model.json\n",
      "n_epoch: 224, max_mem: 800, data: 32, time: 20.71 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1242.558181"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(maze)\n",
    "qtrain(model, maze, epochs=1000, max_memory=8*maze.size, data_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oj3EC2GBDkYu"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAGTklEQVR4nO3dsWrUWRjG4W927DSIQ2BQBmKXxm7sbLTzBrwFr2A68Q6mF72CgBfhXEBSCBamEYs0gliZUv5b7IaVJTqJnmPmTZ4HUmX35Zj4W03z7WgYhgI2318X/QDgbMQKIcQKIcQKIcQKIcQKIa6d5x/e3t4e7t692/QBx8fH9f79+6abVVW3b9+uO3fuNN89Pj6u69evR+wmvTVtt9dbP378WJ8/fx6d+slhGM78MZ/Ph9bevHkzVFXzj+Vy2fytJ+9N2U16a9pur7f+29ip/flrMIQQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4QQK4TYiFh/dHPmdz7m8/lF/7I2wmg0av5xcHBw0b+sK2k0rPkfU41Go6dV9bSqajqdzvf29po+4OvXr3Xjxo2mm3b/2zw8PGy6WVU1m81qOp0230372vZ462KxqP39/c29btiDXZcje+66bgj8kFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhINpl3jXwbR+uw6m2W2+WQ6mOZgG/FlihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRBihRDnivXg4KBGo1HTjx6bJ7s99Hxvj80f3fP5nY/5fB71PbssznXd8ObNm/Pnz583fcBsNqujo6Ommye7PS7wffr0qdt7W+/2vEJ41a8mbvx1w+p0Ka/Xbg8935vyNXA10XVD4CfECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHECiHOFet8Pu9yKa/15slujwt8vd7LP5IuR/7xr8263yjfXzecTqfzvb29pg/odSWu1wW+3d3dLu/tcTUx8brhVb8c2ey64b+X15rqdSWu1wW+Xu913bDvpcuUr63rhnAJiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCiBVCXLvoB5Bp6HCRcbVaxeyuVqume2fhuuE5uW7Y93uWstvrra4bum7YVM/vWcpur7e6bgiXgFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghhFghxKU+mHbVd5PemrbrYJrdjd+0229zGBxMg0tBrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBBCrBDiXNcNt7e35y9evGj6gPF4XLdu3Wq6WZV1Ka/Xbs+3Hh4eNt+dzWZ1dHQUsdvrrYvFooZhOPW64bV1//IwDK+q6lVV1c7OzvDly5emj5tMJvXw4cOmm1VVq9Xqyu/2fOtisWi+u1wuY3Z7vfVn/DUYQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQogVQqy9wfQnjEan3of6Lcvlsh49enSld3u+9eXLl813J5NJzO5kMql1xwZ/xf3793/4uY24bvjhw4emm1VZl/J67fZ863g8br47Ho/r27dvEbu9rnIuFova39/f3OuGKRft0nZ7vnVra6v57mQyqda/v3rt9rrK+TN+ZoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQYoUQaw+mfW9nZ2d49uxZ0wck3d1J201668nukydPmu++fv26y9f2wYMHTTerqh4/flxv3779tYNp/7tuWJPJpOnjxuNx8027/TZ77y6Xyy67Pb627969a7q5zkZcN0z7r3/KbtJbT3Z7XGPs9SfrvXv3mm6u42dWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCCFWCLH2uuH3B9OqareqDhu/YbuqPjfetNtv026/zaqq3WEYtk77xLlOkfYwGo32h2G4b7f9btJb03Yv4q3+GgwhxAohNiHWV3a77Sa9NW33j7/1wn9mBc5mE/5kBc5ArBBCrBBCrBBCrBDib5qruuhPHoStAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rat_cell = random.choice(qmaze.free_cells)\n",
    "qmaze.reset(rat_cell)\n",
    "envstate = qmaze.observe()\n",
    "game_status = 'lose'\n",
    "i=0\n",
    "x = 7\n",
    "q_v = []\n",
    "env_s = []\n",
    "while(game_status != 'win'):\n",
    "    q = model.predict(envstate)\n",
    "    if i>= x and i<3+x:\n",
    "        q_v.append(q[0])\n",
    "        env_s.append(envstate)\n",
    "        \n",
    "    action = np.argmax(q[0])\n",
    "    #   action = np.argmax(model.predict(envstate))\n",
    "    envstate, reward, game_status = qmaze.act(action)\n",
    "    show(qmaze)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    plt.gca().clear()\n",
    "    sleep(0.2)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Left         Up          Right       Down\n",
      "[ 0.16977614 -0.1403308   0.5336234  -0.37354964]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Left         Up          Right       Down\n",
      "[ 0.2814235   0.6327476  -0.539765   -0.50499475]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Left         Up          Right       Down\n",
      "[ 0.24167418  0.08761132  0.7425209  -0.40212566]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAJ/ElEQVR4nO3dz4uchR3H8c+nWUUTKxWyF5PQjSC2IpSYQdSAB+NBq+ilhwgK9ZJL1SiCaC/xDxDRgwgh6sWgh5iDiKgF9dBLcDYRNK5CiGkSjTg5VMVLDH562BXS/JpnZ+fJs/P1/YJAdnccP9nsO8/M7MyzTiIAdfyu6wEAxouogWKIGiiGqIFiiBooZqqNK129enVmZmbGfr2zs7Njv05J2rhxYyvXC7Tl8OHDOnHihM/1sVainpmZUb/fH/v12uf8MyxZG1uBNvV6vfN+jJvfQDFEDRRD1EAxRA0UQ9RAMUQNFNMoatt32v7S9kHbT7U9CsDohkZte4WkFyXdJel6Sffbvr7tYQBG0+RIfZOkg0kOJTkp6Q1J97U7C8ComkS9RtLR094+tvC+/2N7q+2+7f5gMBjXPgCL1CTqcz0386zTpSTZkaSXpDc9Pb30ZQBG0iTqY5LWnfb2WknftDMHwFI1ifpjSdfaXm/7UklbJL3V7iwAoxr6Kq0kp2w/LOk9SSskvZLkQOvLAIyk0Usvk7wj6Z2WtwAYA55RBhRD1EAxRA0UQ9RAMUQNFNPKiQfbws/9ak9bJ3Xk7+zi40gNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UMzRq2+tsf2h7zvYB29suxjAAo2nyo2xPSXoiyT7bv5c0a/tfST5veRuAEQw9Uic5nmTfwu9/lDQnaU3bwwCMZlH3qW3PSNogae85PrbVdt92fzAYjGcdgEVrHLXtKyS9KemxJD+c+fEkO5L0kvSmp6fHuRHAIjSK2vYlmg96V5I97U4CsBRNHv22pJclzSV5rv1JAJaiyZF6k6QHJd1u+5OFX39teReAEQ39llaSf0vyRdgCYAx4RhlQDFEDxRA1UAxRA8U0ee73os3Ozmr+O2GTIcnYr3OS/vxSO58Dqb3PQ1t7K+BIDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0U08rZRDdu3Kh+v9/GVbeijTNeTtrZOSfNJH0eLvaZTzlSA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8U0jtr2Ctv7bb/d5iAAS7OYI/U2SXNtDQEwHo2itr1W0t2SdrY7B8BSNT1SPy/pSUm/nO8Ctrfa7tvuDwaDsYwDsHhDo7Z9j6Tvksxe6HJJdiTpJelNT0+PbSCAxWlypN4k6V7bhyW9Iel226+1ugrAyIZGneTpJGuTzEjaIumDJA+0vgzASPg+NVDMol5PneQjSR+1sgTAWHCkBoohaqAYogaKIWqgGKIGimnlbKLAry72mTTBkRooh6iBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaogWKIGiiGqIFiiBoohqiBYogaKIaziWqyzng5SVvRDY7UQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDGNorb9B9u7bX9he872LW0PAzCapk8+eUHSu0n+ZvtSSStb3ARgCYZGbftKSbdJ+rskJTkp6WS7swCMqsnN72skDSS9anu/7Z22V515Idtbbfdt9weDwdiHAmimSdRTkm6U9FKSDZJ+kvTUmRdKsiNJL0lvenp6zDMBNNUk6mOSjiXZu/D2bs1HDmAZGhp1km8lHbV93cK7Nkv6vNVVAEbW9NHvRyTtWnjk+5Ckh9qbBGApGkWd5BNJvZa3ABgDnlEGFEPUQDFEDRRD1EAxRA0Uw9lE0SrbXU/4zeFIDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxRA0UQ9RAMUQNFEPUQDFEDRRD1EAxE3XiQU5iN3meeeaZVq53+/btrVzvpOj1zv9TsDhSA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8U0itr247YP2P7M9uu2L2t7GIDRDI3a9hpJj0rqJblB0gpJW9oeBmA0TW9+T0m63PaUpJWSvmlvEoClGBp1kq8lPSvpiKTjkr5P8v6Zl7O91Xbfdn8wGIx/KYBGmtz8vkrSfZLWS7pa0irbD5x5uSQ7kvSS9Kanp8e/FEAjTW5+3yHpqySDJD9L2iPp1nZnARhVk6iPSLrZ9krPv0xqs6S5dmcBGFWT+9R7Je2WtE/Spwv/zY6WdwEYUaPXUyfZLum3/QJWYELwjDKgGKIGiiFqoBiiBoohaqCYiTqbaJKuJ2CZaOPMslW+vjhSA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFEDVQDFEDxRA1UAxRA8UQNVAMUQPFuI0zKNoeSPpPg4uulnRi7APaM0l7J2mrNFl7l8PWPyY55w+CbyXqpmz3k/Q6G7BIk7R3krZKk7V3uW/l5jdQDFEDxXQd9aT98PpJ2jtJW6XJ2rust3Z6nxrA+HV9pAYwZkQNFNNZ1LbvtP2l7YO2n+pqxzC219n+0Pac7QO2t3W9qQnbK2zvt/1211suxPYfbO+2/cXC5/iWrjddiO3HF74OPrP9uu3Lut50pk6itr1C0ouS7pJ0vaT7bV/fxZYGTkl6IsmfJd0s6R/LeOvptkma63pEAy9IejfJnyT9Rct4s+01kh6V1Etyg6QVkrZ0u+psXR2pb5J0MMmhJCclvSHpvo62XFCS40n2Lfz+R81/0a3pdtWF2V4r6W5JO7veciG2r5R0m6SXJSnJyST/7XbVUFOSLrc9JWmlpG863nOWrqJeI+noaW8f0zIPRZJsz0jaIGlvt0uGel7Sk5J+6XrIENdIGkh6deGuwk7bq7oedT5Jvpb0rKQjko5L+j7J+92uOltXUfsc71vW31uzfYWkNyU9luSHrvecj+17JH2XZLbrLQ1MSbpR0ktJNkj6SdJyfnzlKs3folwv6WpJq2w/0O2qs3UV9TFJ6057e62W4c2YX9m+RPNB70qyp+s9Q2ySdK/tw5q/W3O77de6nXRexyQdS/LrLZ/dmo98ubpD0ldJBkl+lrRH0q0dbzpLV1F/LOla2+ttX6r5Bxve6mjLBdm25u/zzSV5rus9wyR5OsnaJDOa/7x+kGTZHU0kKcm3ko7avm7hXZslfd7hpGGOSLrZ9sqFr4vNWoYP7E118T9Ncsr2w5Le0/wjiK8kOdDFlgY2SXpQ0qe2P1l43z+TvNPhpkoekbRr4R/3Q5Ie6njPeSXZa3u3pH2a/67Ifi3Dp4zyNFGgGJ5RBhRD1EAxRA0UQ9RAMUQNFEPUQDFEDRTzPxNzOErqFMPBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapa= []\n",
    "j=0\n",
    "for k in range(3):\n",
    "    m = np.zeros(maze.shape)\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i] = env_s[k][0][j:j+m.shape[0]]\n",
    "        j+=m.shape[0]\n",
    "    mapa.append(m)\n",
    "    j=0 \n",
    "print('    Left         Up          Right       Down')\n",
    "print(q_v[0])\n",
    "plt.imshow(mapa[0], cmap = 'gray')\n",
    "plt.show()\n",
    "print('    Left         Up          Right       Down')\n",
    "print(q_v[1])\n",
    "plt.imshow(mapa[1], cmap = 'gray')\n",
    "plt.show()\n",
    "print('    Left         Up          Right       Down')\n",
    "print(q_v[2])\n",
    "plt.imshow(mapa[2], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "palpite.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
